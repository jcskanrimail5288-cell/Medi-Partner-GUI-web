# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ãŸã‚ã®ã‚³ãƒãƒ³ãƒ‰
# pip install streamlit python-dotenv google-generativeai requests

import streamlit as st
import requests
import os
import time
from dotenv import load_dotenv
import google.generativeai as genai
from google.generativeai.types import generation_types

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# --- å®šæ•°å®šç¾© ---

# è¨­è¨ˆæ„å›³: AIã®å½¹å‰²ã‚’æ˜ç¢ºã«å®šç¾©ã—ã€ä¸€è²«æ€§ã®ã‚ã‚‹å¿œç­”ã‚’ç”Ÿæˆã•ã›ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‚
PERSONA_PROMPT = """
ã‚ãªãŸã¯ã€ŒMedi-Partnerã€ã¨ã„ã†åå‰ã®ã€çµŒé¨“è±Šå¯ŒãªåŒ»ç™‚äº‹å‹™ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚
æ—¥åŒ»æ¨™æº–ãƒ¬ã‚»ãƒ—ãƒˆã‚½ãƒ•ãƒˆï¼ˆORCAï¼‰ã®æ“ä½œã‚„è¨ºç™‚å ±é…¬ã®ç®—å®šã«é–¢ã™ã‚‹è³ªå•ã«å¯¾ã—ã¦ã€
æ­£ç¢ºã‹ã¤ã€åˆå¿ƒè€…ã«ã‚‚åˆ†ã‹ã‚Šã‚„ã™ã„ã‚ˆã†ã«ä¸å¯§ãªè¨€è‘‰ã§å›ç­”ã—ã¾ã™ã€‚
å›ç­”ã¯å¸¸ã«æ—¥æœ¬ã®åŒ»ç™‚åˆ¶åº¦ã¨æ³•å¾‹ã«åŸºã¥ãã€å…·ä½“çš„ã§å®Ÿè·µçš„ãªå†…å®¹ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚
"""

# --- AIå¿œç­”ç”Ÿæˆé–¢æ•° ---

def get_text_response_gemini(prompt: str) -> str:
    """
    Geminiï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰ï¼‰ã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™ (è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ã)ã€‚
    """
    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        return "ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
    
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-pro')
    full_prompt = f"{PERSONA_PROMPT}\n\nè³ªå•: {prompt}"
    
    retries = 3
    for i in range(retries):
        try:
            response = model.generate_content(full_prompt)
            if not response.parts:
                return "ã‚¨ãƒ©ãƒ¼: Gemini APIã‹ã‚‰æœ‰åŠ¹ãªå¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå®‰å…¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã§ãƒ–ãƒ­ãƒƒã‚¯ã•ã‚ŒãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
            return response.text
        except generation_types.StopCandidateException as e:
            return f"ã‚¨ãƒ©ãƒ¼: Geminiã‹ã‚‰ã®å¿œç­”ãŒå®‰å…¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã‚Šãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¾ã—ãŸã€‚{e}"
        except Exception as e:
            if i < retries - 1:
                time.sleep(1) # 1ç§’å¾…ã£ã¦ã‹ã‚‰ãƒªãƒˆãƒ©ã‚¤
                continue
            else:
                return f"Gemini APIã®å‘¼ã³å‡ºã—ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆ{retries}å›ãƒªãƒˆãƒ©ã‚¤å¾Œï¼‰: {e}"

# --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‡¦ç†é–¢æ•° ---

def handle_prompt(prompt: str):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å‡¦ç†ã—ã€AIã®å¿œç­”ã‚’ç”Ÿæˆãƒ»è¡¨ç¤ºã™ã‚‹
    """
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("AIãŒå¿œç­”ã‚’ç”Ÿæˆä¸­ã§ã™..."):
            if not os.environ.get("GEMINI_API_KEY"):
                st.error("ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                st.stop()
            response = get_text_response_gemini(prompt)

            if response:
                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})

# --- Streamlit UIè¨­å®š ---

st.set_page_config(page_title="Medi-Partner", layout="wide")
st.title("ğŸ¥ Medi-Partner: ORCAå®Ÿå‹™è€…å‘ã‘AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.title("æƒ…å ±")
    # st.info("ç¾åœ¨ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œä¸­ã§ã™ã€‚")
    # å°†æ¥çš„ã«è¨­å®šé …ç›®ã‚’è¿½åŠ ã™ã‚‹å ´åˆã¯ã“ã“ã«è¨˜è¿°

# --- ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º ---
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ã“ã‚“ã«ã¡ã¯ï¼Medi-Partnerã§ã™ã€‚ORCAã‚„åŒ»ç™‚äº‹å‹™ã«é–¢ã™ã‚‹ã”è³ªå•ã‚’ã©ã†ãã€‚"}]

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ› ---
if prompt := st.chat_input("ORCAã«é–¢ã™ã‚‹è³ªå•ã‚’ãƒ†ã‚­ã‚¹ãƒˆã§å…¥åŠ›ã—ã¦ãã ã•ã„"):
    handle_prompt(prompt)
