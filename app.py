# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ãŸã‚ã®ã‚³ãƒãƒ³ãƒ‰
# pip install streamlit python-dotenv google-generativeai requests

import streamlit as st
import os
import re
from dotenv import load_dotenv
import google.generativeai as genai

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# --- å®šæ•°å®šç¾© ---

# AIã¸ã®æŒ‡ç¤ºï¼ˆã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰
SYSTEM_INSTRUCTION = """
ã‚ãªãŸã¯ã€ŒMedi-Partnerã€ã¨ã„ã†ã€åŒ»ç™‚äº‹å‹™ã«è©³ã—ã„AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¨ã€é–¢é€£ã™ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹ãƒãƒ‹ãƒ¥ã‚¢ãƒ«é …ç›®ãŒæä¾›ã•ã‚Œã¾ã™ã€‚
ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã‚’å³å¯†ã«å®ˆã£ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚

1. æä¾›ã•ã‚ŒãŸã€Œé–¢é€£ãƒãƒ‹ãƒ¥ã‚¢ãƒ«é …ç›®ã€ãƒªã‚¹ãƒˆã®ä¸­ã‹ã‚‰ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„ã‚‚ã®ã‚’**1ã¤ã ã‘**é¸ã‚“ã§ãã ã•ã„ã€‚
2. é¸ã‚“ã é …ç›®ã®**ç•ªå·éƒ¨åˆ†**ï¼ˆä¾‹: `2.2`ï¼‰ã‚’ç‰¹å®šã—ã¾ã™ã€‚
3. ç‰¹å®šã—ãŸç•ªå·ã¨ã€æŒ‡å®šã•ã‚ŒãŸã€Œãƒãƒ‹ãƒ¥ã‚¢ãƒ«ç¨®åˆ¥ã€ï¼ˆ`gairai` ã¾ãŸã¯ `nyuin`ï¼‰ã‚’ä½¿ã£ã¦ã€ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã§URLã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
    *   **URLå½¢å¼**: `https://orcamanual.orca.med.or.jp/[ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ç¨®åˆ¥]/chapter/[å¤‰æ›å¾Œã®ç« ç•ªå·]/`
    *   **å¤‰æ›ãƒ«ãƒ¼ãƒ«**: ç« ç•ªå·ã«å«ã¾ã‚Œã‚‹ `.` ã‚’ `-` ã«ç½®ãæ›ãˆã¾ã™ã€‚ï¼ˆä¾‹: `2.2` ã¯ `2-2` ã«ãªã‚Šã¾ã™ï¼‰
4. ç”Ÿæˆã—ãŸURLã®æƒ…å ±ã‚’åŸºã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
5. å›ç­”ã®æœ€å¾Œã«ã¯ã€**å¿…ãšç”Ÿæˆã—ãŸURLã‚’ã€Œå‚è€ƒãƒªãƒ³ã‚¯ï¼šã€ã¨ã—ã¦è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚**
6. ã‚‚ã—ãƒªã‚¹ãƒˆå†…ã«é©åˆ‡ãªé …ç›®ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ã€Œã”è³ªå•ã«é–¢é€£ã™ã‚‹ãƒãƒ‹ãƒ¥ã‚¢ãƒ«é …ç›®ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã€ã¨ã ã‘å›ç­”ã—ã¦ãã ã•ã„ã€‚
"""

# ORCAãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã®ç›®æ¬¡ãƒ‡ãƒ¼ã‚¿
GAIRAI_TOC = {
    "1.1": "glclient2ã«ã¤ã„ã¦", "1.2": "ãƒã‚¹ã‚¿ãƒ¼ãƒ¡ãƒ‹ãƒ¥ãƒ¼", "1.3": "æ¥­å‹™ãƒ¡ãƒ‹ãƒ¥ãƒ¼",
    "2.1": "å—ä»˜", "2.2": "ç™»éŒ²(æ‚£è€…ç™»éŒ²ã«ã¤ã„ã¦)", "2.3": "ç…§ä¼š", "2.4": "äºˆç´„", "2.5": "è¨ºç™‚è¡Œç‚º", "2.6": "è¨ºç™‚åŒºåˆ†åˆ¥ã®å…¥åŠ›æ–¹æ³•", "2.7": "ç—…å", "2.8": "åç´", "2.9": "ä¼šè¨ˆç…§ä¼š", "2.10": "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå°åˆ·",
    "3.1": "ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯", "3.2": "æ˜ç´°æ›¸", "3.3": "è«‹æ±‚ç®¡ç†", "3.4": "ç·æ‹¬è¡¨ãƒ»å…¬è²»è«‹æ±‚æ›¸", "3.5": "æ—¥æ¬¡çµ±è¨ˆ", "3.6": "æœˆæ¬¡çµ±è¨ˆ", "3.7": "çœåºå¯¾å¿œ", "3.8": "æœ¬é™¢åˆ†é™¢æ©Ÿèƒ½", "3.9": "æ²»é¨“", "3.10": "ãƒ¦ãƒ¼ã‚¶ç®¡ç†", "3.11": "å¥åº·ä¿é™ºçµ„åˆãƒ»å…±æ¸ˆçµ„åˆã¸ã®ç›´æ¥è«‹æ±‚", "3.12": "å…¬è²»è¨˜è¼‰é †è¨­å®š", "3.13": "åŠ´ç½ãƒ¬ã‚»ãƒ—ãƒˆé›»ç®—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã«ã¤ã„ã¦", "3.14": "EFãƒ•ã‚¡ã‚¤ãƒ«ãƒ»æ§˜å¼4",
    "4.1": "ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›", "4.2": "å¤–éƒ¨åª’ä½“", "4.3": "ãƒã‚¹ã‚¿æ›´æ–°",
    "5.1": "ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†ãƒã‚¹ã‚¿", "5.2": "ç‚¹æ•°ãƒã‚¹ã‚¿", "5.3": "ãƒ¦ãƒ¼ã‚¶ãŒè‡ªç”±ã«ç™»éŒ²ã§ãã‚‹ãƒã‚¹ã‚¿ã«ã¤ã„ã¦", "5.4": "ãƒã‚§ãƒƒã‚¯ãƒã‚¹ã‚¿", "5.5": "ä¿é™ºç•ªå·ãƒã‚¹ã‚¿", "5.6": "ä¿é™ºè€…ãƒã‚¹ã‚¿", "5.7": "äººåè¾æ›¸ãƒã‚¹ã‚¿", "5.8": "è–¬å‰¤æƒ…å ±ãƒã‚¹ã‚¿", "5.9": "ä½æ‰€ãƒã‚¹ã‚¿", "5.10": "ãƒ˜ãƒ«ãƒ—ãƒã‚¹ã‚¿",
    "6.1": "ä»˜éŒ²1", "6.2": "ä»˜éŒ²2", "6.3": "ä»˜éŒ²3", "6.4": "ä»˜éŒ²4", "6.5": "ä»˜éŒ²5",
    "7.1": "å¯¾å‡¦äº‹ä¾‹1", "7.2": "å¯¾å‡¦äº‹ä¾‹2", "7.3": "å¯¾å‡¦äº‹ä¾‹3", "7.4": "æ–°å‹ã‚³ãƒ­ãƒŠã‚¦ã‚¤ãƒ«ã‚¹æ„ŸæŸ“ç—‡ã«ä¿‚ã‚‹PCRæ¤œæŸ»"
}

NYUIN_TOC = {
    "1.1": "å…¥é™¢æ¥­å‹™ãƒ¡ãƒ‹ãƒ¥ãƒ¼", "1.2": "ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†æƒ…å ±ã®ç™»éŒ²ã«ã¤ã„ã¦", "1.3": "ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†æƒ…å ±ã®ç™»éŒ²",
    "2.1": "å…¥é€€é™¢ç™»éŒ²", "2.2": "å…¥é™¢ä¼šè¨ˆç…§ä¼šã«ã¤ã„ã¦", "2.3": "å…¥é™¢è¨ºç™‚è¡Œç‚ºå…¥åŠ›", "2.4": "åç´ç”»é¢ã‹ã‚‰ã®è«‹æ±‚å–æ¶ˆã—ã«ã¤ã„ã¦", "2.5": "é¸å®šå…¥é™¢æ–™ã«ã¤ã„ã¦", "2.6": "90æ—¥ã‚’è¶…ãˆã‚‹æ‚£è€…ã®å…¥é™¢æ–™ã«ã¤ã„ã¦", "2.7": "å…¥é™¢è¨ºç™‚è¡Œç‚ºç”»é¢ã‹ã‚‰ã®å…¥é™¢å‡¦æ–¹ã›ã‚“å°åˆ·ã«ã¤ã„ã¦", "2.8": "å…¥é™¢è¨ºç™‚è¡Œç‚ºç”»é¢ã‹ã‚‰ã®ãŠè–¬æ‰‹å¸³ç­‰å°åˆ·ã«ã¤ã„ã¦", "2.9": "æ¨™æ¬ ã«ã‚ˆã‚‹æ¸›é¡", "2.10": "å®šæ•°è¶…éå…¥é™¢", "2.11": "çŸ­æœŸæ»åœ¨æ‰‹è¡“ç­‰åŸºæœ¬æ–™3ã«ã¤ã„ã¦", "2.12": "æ€¥æ€§å¢—æ‚ªã«ã‚ˆã‚‹ä»‹è­·ç—…æ£Ÿã‹ã‚‰ã®ç•°å‹•ã«ã¤ã„ã¦", "2.13": "ä¸€èˆ¬ãƒ»ç™‚é¤Šç›¸äº’ç®—å®šã«ã¤ã„ã¦",
    "3.1": "å…¥é™¢å®šæœŸè«‹æ±‚", "3.2": "å…¥é™¢ä¼šè¨ˆä¸€æ‹¬ä½œæˆã«ã¤ã„ã¦",
    "4.1": "é€€é™¢æ™‚ä»®è¨ˆç®—ã«ã¤ã„ã¦", "4.2": "æ‚£è€…ç…§ä¼šã«ã¤ã„ã¦",
    "5.1": "ãƒ¬ã‚»ãƒ—ãƒˆä½œæˆã«ã¤ã„ã¦", "5.2": "å…¥é™¢ãƒ¬ã‚»ãƒ—ãƒˆã®ã‚³ãƒ¡ãƒ³ãƒˆè‡ªå‹•è¨˜è¼‰ã«ã¤ã„ã¦", "5.3": "ç¦å²¡çœŒã®å…¥é™¢ãƒ¬ã‚»ãƒ—ãƒˆå¯¾å¿œã«ã¤ã„ã¦",
    "6.1": "æ’ä»–åˆ¶å¾¡",
    "7.1": "å…¥é™¢ç™»éŒ²æ™‚ã®è¨‚æ­£æ–¹æ³•ç­‰ã«ã¤ã„ã¦", "7.2": "å‡ºç”£è‚²å…ä¸€æ™‚é‡‘ç­‰ã®åŒ»ç™‚æ©Ÿé–¢ã¸ã®ç›´æ¥æ”¯æ‰•åˆ¶åº¦", "7.3": "å…¥é™¢æœŸé–“ä¸­ã®å¤–æ¥å…¥åŠ›", "7.4": "åŒ»ç™‚è¦³å¯Ÿæ³•", "7.5": "å…¥é™¢ã‚ªãƒ¼ãƒ€ãƒ¼", "7.6": "å›å¾©æœŸãƒªãƒãƒ“ãƒªãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç—…æ£Ÿå…¥é™¢æ–™ã®ç–¾æ‚£åˆ¥ãƒªãƒãƒ“ãƒªãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ–™åŒ…æ‹¬å…¥åŠ›", "7.7": "æ–°å‹ã‚³ãƒ­ãƒŠã‚¦ã‚¤ãƒ«ã‚¹æ„ŸæŸ“ç—‡å…¥é™¢å¯¾å¿œ",
    "8.1": "æ—¥æ¬¡çµ±è¨ˆå¸³ç¥¨ã«ã¤ã„ã¦",
    "9.1": "æœˆæ¬¡çµ±è¨ˆå¸³ç¥¨ã«ã¤ã„ã¦",
    "10.1": "å…¥é™¢å®¤æ–™åŠ ç®—ã®è¨­å®š", "10.2": "å…¥é™¢é£Ÿäº‹ç™‚é¤Šè²»ã®è¨­å®šï¼ˆè‡ªè³ è²¬ã®ã¿ï¼‰"
}

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---

def find_relevant_sections(query: str, toc: dict) -> list[str]:
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¨ç›®æ¬¡ã‹ã‚‰ã€é–¢é€£æ€§ã®é«˜ã„é …ç›®ã‚’ã„ãã¤ã‹æŠ½å‡ºã™ã‚‹ã€‚
    """
    scores = []
    query_words = set(re.findall(r'[ä¸€-é¾ ã-ã‚“ã‚¡-ãƒ³A-Za-z0-9]+', query))
    
    for key, section in toc.items():
        section_words = set(re.findall(r'[ä¸€-é¾ ã-ã‚“ã‚¡-ãƒ³A-Za-z0-9]+', section))
        score = len(query_words.intersection(section_words))
        if score > 0:
            scores.append((score, f"{key} {section}"))
    
    scores.sort(key=lambda x: x[0], reverse=True)
    return [section for score, section in scores[:3]]

# --- AIå¿œç­”ç”Ÿæˆé–¢æ•° ---

def get_text_response_gemini(prompt: str) -> str:
    """
    ãƒ­ãƒ¼ã‚«ãƒ«ã§ã®ç›®æ¬¡æ¤œç´¢ã¨ã€Gemini APIå‘¼ã³å‡ºã—ã‚’çµ„ã¿åˆã‚ã›ãŸ2æ®µéšå‡¦ç†ã§å¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    """
    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        return "ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
    
    genai.configure(api_key=api_key)

    # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ­ãƒ¼ã‚«ãƒ«æ¤œç´¢
    if any(keyword in prompt for keyword in ["å…¥é™¢", "é€€é™¢", "ç—…æ£Ÿ", "å…¥é™¢æ–™"]):
        toc = NYUIN_TOC
        manual_type = "nyuin"
    else:
        toc = GAIRAI_TOC
        manual_type = "gairai"
    
    relevant_sections = find_relevant_sections(prompt, toc)

    # ã‚¹ãƒ†ãƒƒãƒ—2: AIã¸ã®æŒ‡ç¤º
    context_message = f"ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ç¨®åˆ¥: {manual_type}\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: ã€Œ{prompt}ã€\n"
    if relevant_sections:
        context_message += "\né–¢é€£ãƒãƒ‹ãƒ¥ã‚¢ãƒ«é …ç›®:\n- " + "\n- ".join(relevant_sections)
    else:
        return "é–¢é€£ã™ã‚‹ãƒãƒ‹ãƒ¥ã‚¢ãƒ«é …ç›®ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚è³ªå•ã‚’å¤‰ãˆã¦ãŠè©¦ã—ãã ã•ã„ã€‚"

    try:
        model = genai.GenerativeModel(
            'gemini-1.5-flash-latest',
            system_instruction=SYSTEM_INSTRUCTION
        )
        response = model.generate_content(context_message)
        return response.text
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼: Gemini APIã®å‘¼ã³å‡ºã—ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ {e}"

# --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‡¦ç†é–¢æ•° ---

def handle_prompt(prompt: str):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å‡¦ç†ã—ã€AIã®å¿œç­”ã‚’ç”Ÿæˆãƒ»è¡¨ç¤ºã™ã‚‹
    """
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("AIãŒå¿œç­”ã‚’ç”Ÿæˆä¸­ã§ã™..."):
            response = get_text_response_gemini(prompt)
            st.markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response})

# --- Streamlit UIè¨­å®š ---

st.set_page_config(page_title="Medi-Partner", layout="wide")
st.title("ğŸ¥ Medi-Partner: ORCAå®Ÿå‹™è€…å‘ã‘AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.title("æƒ…å ±")

# --- ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º ---
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ã“ã‚“ã«ã¡ã¯ï¼Medi-Partnerã§ã™ã€‚ORCAã‚„åŒ»ç™‚äº‹å‹™ã«é–¢ã™ã‚‹ã”è³ªå•ã‚’ã©ã†ãã€‚"}]

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ› ---
if prompt := st.chat_input("ORCAã«é–¢ã™ã‚‹è³ªå•ã‚’ãƒ†ã‚­ã‚¹ãƒˆã§å…¥åŠ›ã—ã¦ãã ã•ã„"):
    handle_prompt(prompt)
